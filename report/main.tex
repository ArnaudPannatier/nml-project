\documentclass[a4paper,10pt]{article}
\usepackage[%
% bw,                               % uncomment for black & white
% window,                           % uncomment for window envelope
% corporate,                        % uncomment for a "corporate" letter
  ]{EPFL}
  %\def\familydefault{\rmdefault}    % uncomment for serif fonts in body
  \narrowmargins                    % uncomment for narrow margins
  \symmetricmargins                 % uncomment for equal margins
  \unitname{%                         % footer, typically Faculty
  EDIC \\
  Idiap Research Institute \\
  Machine Learning Group
  }{}{}
\usepackage[document]{ragged2e}
\usepackage{anyfontsize}
\usepackage{titling}
\usepackage{amsfonts}
\usepackage{xcolor}

\definecolor{blue}{HTML}{2980b9}
\definecolor{gray}{HTML}{7f8c8d}
\definecolor{green}{HTML}{16a085}
\definecolor{orange}{HTML}{d35400}
\definecolor{purple}{HTML}{8e44ad}
\definecolor{red}{HTML}{c0392b}


\newcommand{\ap}[1]{\marginpar{{\tiny \color{purple} [AP] #1}}}

\title{Graph Networks for Wind Nowcasting}
\author{Arnaud Pannatier}
\begin{document}
\centering
\vspace*{0cm}
{\fontsize{35}{60}\selectfont \bfseries \thetitle } \\
\vspace{1cm}
\Large \textit{EE-452 -- project} \\
\vspace{0.5cm}
\normalfont
\Large \theauthor \\
\vspace{0.5cm}

\small\today

\normalfont\normalsize

\justifying

\section{Introduction}

Air Traffic Controllers (ATC) need to have access to reliable wind speed forecasts to organize the airspace efficiently. However, at cruising altitudes, the only measures that one has access to are measured by airplanes that record the wind along their trajectories. Therefore, air traffic controllers need to have very short-term forecasts of about 30 minutes. In that range, called nowcasting, one gets the most accurate forecast by extrapolating from the latest measures available rather than trying to solve expensive numerical equations solvers. It is in that range that deep learning methods can offer a lot, as meteorological data is often highly available, and deep learning methods thrive in that environment.

\section{Related works}

\subsection{Finite Element Networks}

Traditional PDEs solvers are model the domain using regular grids, but this has some drawbacks as some part of the space might be more complicated to model than the other. One way of dealing with this problem is to use a Finite Element method approach \cite{hughes2012finite}, which uses a non-regular graph that can be denser in the more complex regions and coarser in the smoother regions.

\subsection{Graph Element Networks (GENs)}
Graph Element Networks \cite{alet2019gen} aim to model SFTs using a non-regular graphs with nodes in the underlying space $\mathbb{X}$. Each measurement $(x, i)$ is encoded using a small MLP and contributes to the neighbouring nodes values. The model then process this latent variable using $T \in \mathbb{N}$ steps of message passing, the exact formulation of its message passing scheme can be found in the appendix.
In order to predict at a new query position, the model linearly extrapolates in latent space, and decodes using a small MLP modelling the transformation from latent to output space.

\section{Problem formulation}

\section{Exploration}
% (30 points)
% The goal of this section is to analyze the data, and get insights about the tools that will help in the learning section: what handcrafted features could be useful? If you use graph neural networks, what parametrization should be used?

\begin{itemize}
  \item We want our graph to represent the state of the space
  \item Features : field values
  \item Edge features : derivatives ?
  \item Setting up the graph : Kmeans + nearest neighbors // scale free network based on the variation of the field
  \item Connected graph
  \item Expect local connections but ablation
  \item comment on diameter and degree distribution
  \item display visualization of the two networks
  \item Compare with traditional Finite Element method
\end{itemize}

\subsection{Graph Types}

Usually the mesh for FEM simulations is created beforehand with denser region where we expect the field to behave more complicated way. Meshes for this simulation are usually a triangulation of the region of interest. The triangulation subdivise the space into non overlapping triangles, such that each triangle have either a side or a vertex in common or are disjoint. A density parameter define the finess of the triangulation. The graph generated by such this triangulation scheme is such that there is an edge between two nodes only if there are close in the euclidean sense. The degree distribution of these graphs has only small values corresponding to the local neighborhood.

\ap{TODO : graph}

For GENs, the original way of creating graphs is to create a grid mesh that covers the whole space, and to encode the node position as parameters of the model, so that it can be optimized by gradient descent during training. In that case, the graph structure remains similar to the initial grid structure.

\ap{TODO : graph}

In both apporaches, only those graph structures have been used. In this work, we will consider three approaches for our graph topology. The first one, considered as baseline is constructed as follow : First we will take the $k$-means of the measure positions and we will add edges between the nearest neighbors. The second one will be a random network were the nodes position and their edges are taken at random, we will try different parameters $p$ and analyse its effect on the quality of the model.

We will use a totally different approaches for the last graph structure, we will try to design a custom Barab\'asi-Albert model.
\ap{TODO : graph}


\subsection{Features}




% You are free to use the tools that you want. We list below some examples of properties that you can analyze:
% \begin{itemize}
%     \item global properties of the graph (e.g., connected components, sparsity, diameter, clusters, degree distribution, spectrum)
%     \item the type of graph (e.g., power law, small world, regular, sampled manifold)
%     \item properties of the nodes (e.g., clustering coefficient, modularity, centrality)
%     \item analysis of the attributes (e.g., their distribution, smoothness, graph Fourier transform). If the task is classification, are the labels balanced?
%     \item clustering (spectral clustering, k-means)
% \end{itemize}
% Vizualizations of the network may be very helpful
\section{Exploitation}
% (40 points)

% If you plan to use graph neural networks to solve a task, remember that extensive cross validation of the architecture is expensive and may not be very informative. It it therefore important to spend time beforehand to understand what architecture should work well: what aggregation function is the most relevant for this data? What matters most: the graph structure itself, the node features, the edge features?

Here the node features is the most informative, maybe the edge features depending on the exploration of 1.

% You can also consider simple baselines such as logisitic regression on preprocessed features. Such baselines are often quite strong, and can give a good idea of the performance of your graph network.

Have a good baseline.

% Some tools that may be useful:

% \begin{itemize}
%     \item graph Fourier transform
%     \item regularization (graph Tikhonov, graph total variation)
%     \item dimensionality reduction (PCA, MDS, LLE, ISOMAP, Laplacian eigenmaps, t-SNE)
% \end{itemize}

% Critical evaluation of the results
% subjective or objective (baseline, existing work)
% state the limitations: when does the method fail?

% We insist on the fact that you will be graded based on the process that led you to your final model, but not so much on the final performance that you get.

\section{Communication}
% (30 points)


\begin{itemize}
  \item Good report
  \item Github
  \item Streamlit
\end{itemize}

\bibliographystyle{apalike}
\bibliography{main}

\end{document}