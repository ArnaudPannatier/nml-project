
@InProceedings{alet2019gen,
  title = 	 {Graph Element Networks: adaptive, structured computation and memory},
  author =       {Alet, Ferran and Jeewajee, Adarsh Keshav and Villalonga, Maria Bauza and Rodriguez, Alberto and Lozano-Perez, Tomas and Kaelbling, Leslie},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {212--222},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/alet19a/alet19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/alet19a.html},
  abstract = 	 {We explore the use of graph neural networks (GNNs) to model spatial processes in which there is no a priori graphical structure. Similar to finite element analysis, we assign nodes of a GNN to spatial locations and use a computational process defined on the graph to model the relationship between an initial function defined over a space and a resulting function in the same space. We use GNNs as a computational substrate, and show that the locations of the nodes in space as well as their connectivity can be optimized to focus on the most complex parts of the space. Moreover, this representational strategy allows the learned input-output relationship to generalize over the size of the underlying space and run the same model at different levels of precision, trading computation for accuracy. We demonstrate this method on a traditional PDE problem, a physical prediction problem from robotics, and learning to predict scene images from novel viewpoints.}
}
@book{hughes2012finite,
  title={The finite element method: linear static and dynamic finite element analysis},
  author={Hughes, Thomas JR},
  year={2012},
  publisher={Courier Corporation}
}
@inproceedings{vaswani2017attention,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@article{chu2021conditional,
  title={Conditional positional encodings for vision transformers},
  author={Chu, Xiangxiang and Tian, Zhi and Zhang, Bo and Wang, Xinlong and Wei, Xiaolin and Xia, Huaxia and Shen, Chunhua},
  journal={arXiv preprint arXiv:2102.10882},
  year={2021}
}
@misc{skysoft2021dataset,
  author       = {Berling, Didier and Pannatier, Arnaud and Fleuret, Fran√ßois},
  title        = {SkySoft ATM MALAT wind speed},
  month        = jul,
  year         = 2021,
  publisher    = {Zenodo},
  doi          = {10.34777/tqga-m850},
  url          = {https://doi.org/10.34777/tqga-m850}
}
@inproceedings{pfaff2020learning,
  title={Learning Mesh-Based Simulation with Graph Networks},
  author={Pfaff, Tobias and Fortunato, Meire and Sanchez-Gonzalez, Alvaro and Battaglia, Peter},
  booktitle={International Conference on Learning Representations},
  year={2020}
}
@book{meister2004fluids,
  title={Physique des Fluides},
  author={Jean\-Jacques Meister},
  year={2004},
}
 @misc{ wiki:cranknicolson,
   author = "{Wikipedia contributors}",
   title = "Crank-Nicolson method --- {W}ikipedia{,} The Free Encyclopedia",
   year = "2004",
   url = "https://en.wikipedia.org/wiki/Crank%E2%80%93Nicolson_method",
   note = "[Online; accessed 08-June-2022]"
 }